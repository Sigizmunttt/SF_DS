{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                ПОРЯДКОВОЕ КОДИРОВАНИЕ. ORDINAL ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce # импортируем библиотеку для работы с кодировщиками\n",
    "\n",
    "ord_encoder = ce.OrdinalEncoder()\n",
    "data_bin = ord_encoder.fit_transform(clothing[['size']])\n",
    "clothing = pd.concat([clothing, data_bin], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                         НОМИНАЛЬНОЕ КОДИРОВАНИЕ. ONE-HOT ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce # импорт для работы с кодировщиком\n",
    "\n",
    "encoder = ce.OneHotEncoder(cols=['type'], use_cat_names=True) # указываем столбец для кодирования, use_cat_names - оставляем названия категорий как они указаны. Без этого будет type_1, type_2 b nl\n",
    "type_bin = encoder.fit_transform(clothing['type'])\n",
    "clothing = pd.concat([clothing, type_bin], axis=1)\n",
    "\n",
    "ИЛИ\n",
    "\n",
    "clothing_dummies = pd.get_dummies(clothing, columns=['type'])\n",
    "Новые бинарные признаки также часто называются dummy-признаками или dummy-переменными.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                              ДВОИЧНОЕ КОДИРОВАНИЕ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce # импорт для работы с кодировщиком\n",
    "bin_encoder = ce.BinaryEncoder(cols=['type']) # указываем столбец для кодирования\n",
    "type_bin = bin_encoder.fit_transform(clothing['type'])\n",
    "clothing = pd.concat([clothing, type_bin], axis=1)\n",
    "\n",
    "clothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                 НОРМАЛИЗАЦИЯ MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "mm_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "# кодируем исходный датасет\n",
    "df_mm = mm_scaler.fit_transform(df)\n",
    "\n",
    "# Преобразуем промежуточный датасет в полноценный датафрейм для визуализации\n",
    "df_mm = pd.DataFrame(df_mm, columns=col_names)\n",
    "\n",
    "fig, (ax1) = plt.subplots(ncols=1, figsize=(10, 8))\n",
    "ax1.set_title('После нормализации MinMaxScaler')\n",
    "\n",
    "sns.kdeplot(df_mm['beta'], ax=ax1)\n",
    "sns.kdeplot(df_mm['exponential'], ax=ax1)\n",
    "sns.kdeplot(df_mm['normal_p'], ax=ax1)\n",
    "sns.kdeplot(df_mm['normal_l'], ax=ax1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![МинМакс](MinMax.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                             НОРМАЛИЗАЦИЯ ROBUSTSCALER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "# инициализируем нормализатор RobustScaler\n",
    "r_scaler = preprocessing.RobustScaler()\n",
    "\n",
    "# кодируем исходный датасет\n",
    "df_r = r_scaler.fit_transform(df)\n",
    "\n",
    "# Преобразуем промежуточный датасет в полноценный датафрейм для визуализации\n",
    "df_r = pd.DataFrame(df_r, columns=col_names)\n",
    "\n",
    "fig, (ax1) = plt.subplots(ncols=1, figsize=(10, 8))\n",
    "ax1.set_title('Распределения после RobustScaler')\n",
    "\n",
    "sns.kdeplot(df_r['beta'], ax=ax1)\n",
    "sns.kdeplot(df_r['exponential'], ax=ax1)\n",
    "sns.kdeplot(df_r['normal_p'], ax=ax1)\n",
    "sns.kdeplot(df_r['normal_l'], ax=ax1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Robust](robust.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                           СТАНДАРТИЗАЦИЯ ДАННЫХ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализируем стандартизатор StandardScaler\n",
    "s_scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# кодируем исходный датасет\n",
    "df_s = s_scaler.fit_transform(df)\n",
    "\n",
    "# Преобразуем промежуточный датасет в полноценный датафрейм для визуализации\n",
    "df_s = pd.DataFrame(df_s, columns=col_names)\n",
    "\n",
    "fig, (ax1) = plt.subplots(ncols=1, figsize=(10, 8))\n",
    "ax1.set_title('Распределения после StandardScaler')\n",
    "\n",
    "sns.kdeplot(df_s['beta'], ax=ax1)\n",
    "sns.kdeplot(df_s['exponential'], ax=ax1)\n",
    "sns.kdeplot(df_s['normal_p'], ax=ax1)\n",
    "sns.kdeplot(df_s['normal_l'], ax=ax1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Стандарт](standart.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                             ОТОБРАЖЕНИЕ КОРРЕЛЯЦИИ ПРИЗНАКОВ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns # импортируем seaborn для построения графиков\n",
    "sns.heatmap(iris.corr(), annot=True) # включаем отображение коэффициентов\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                  -------------------ПАРАМЕТРИЧЕСКИЕ ТЕСТЫ-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                       ТЕСТ ШАПИРО НА НОРМАЛЬНОСТЬ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# задаём уровень значимости\n",
    "alpha = 0.05 \n",
    "\n",
    "# загружаем данные\n",
    "data = [12,  8,  9, 10, 11, 12,  7, 12,  2, 10,  3,  9, 18, 4, 11, 13, 13, 17, 14,  3, 10,  2,  2,  7, 14,  8, 20,  5,  7, 10]\n",
    "\n",
    "# проводим тест Шапиро — Уилка\n",
    "_, p = stats.shapiro(data)\n",
    "\n",
    "print('p-value = %.3f' % (p))\n",
    "\n",
    "# интерпретируем результат\n",
    "if p <= alpha:\n",
    "    print('Распределение не нормальное')\n",
    "else:\n",
    "    print('Распределение нормальное')\n",
    "\n",
    "# p-value = 0.015\n",
    "# Распределение не нормальное\n",
    "(Нулевая гипотеза - нормальное, альтернативная - нет)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                    ОДНОВЫБОРОЧНЫЙ T-КРИТЕРИЙ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# задаём уровень значимости\n",
    "alpha = 0.05 \n",
    "\n",
    "# загружаем данные\n",
    "data = [41, 38, 40, 46, 40, 46, 41, 44, 43, 39, 36, 41, 37, 45, 38, 45, 38, 48, 42, 34]\n",
    "\n",
    "# проводим тест\n",
    "_, p = stats.ttest_1samp(data, popmean=40, alternative='greater')\n",
    "\n",
    "print('p-value = {:.3f}'.format(p))\n",
    "\n",
    "# интерпретируем результат\n",
    "if p <= alpha:\n",
    "    print('p-значение меньше, чем заданный уровень значимости {:.2f}. Отвергаем нулевую гипотезу.'.format(alpha))\n",
    "else:\n",
    "    print('p-значение больше, чем заданный уровень значимости {:.2f}. У нас нет оснований отвергнуть нулевую гипотезу.'.format(alpha))\n",
    "\n",
    "# p-value = 0.103\n",
    "# p-значение больше, чем заданный уровень значимости 0.05. У нас нет оснований отвергнуть нулевую гипотезу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                     ДВУХВЫБОРОЧНЫЙ T-КРИТЕРИЙ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "# задаём уровень значимости\n",
    "alpha = 0.05 \n",
    "\n",
    "# загружаем данные\n",
    "data_zaryad = np.array([41,38,40,46,40,46,41,44,43,39,36,41,37,45,38,45,38,48,42,34])\n",
    "data_planeta = np.array([40,39,42,46,41,46,42,45,44,42,38,42,38,46,39,46,40,41,43,36])\n",
    "\n",
    "# проводим тест Левена на равенство дисперсий\n",
    "print('Тест на равенство дисперсий')\n",
    "result = stats.levene(data_planeta, data_zaryad)\n",
    "p = result[1]\n",
    "print('p-value = {:.3f}'.format(p))\n",
    "\n",
    "# интерпретируем результат\n",
    "if p <= alpha:\n",
    "    print('Дисперсии не одинаковы, в stats.ttest_ind нужно использовать параметр equal_var=False.')\n",
    "else:\n",
    "    print('Дисперсии одинаковы, в stats.ttest_ind нужно использовать параметр equal_var=True.')\n",
    "\n",
    "# проводим тест на сравнение средних в группах\n",
    "print('\\nТест на равенство средних')\n",
    "_, p = stats.ttest_ind(data_planeta, data_zaryad, alternative='greater', equal_var=True)\n",
    "\n",
    "print('p-value = {:.3f}'.format(p))\n",
    "\n",
    "# интерпретируем результат\n",
    "if p <= alpha:\n",
    "    print('p-значение меньше, чем заданный уровень значимости {:.2f}. Отвергаем нулевую гипотезу.'.format(alpha))\n",
    "else:\n",
    "    print('p-значение больше, чем заданный уровень значимости {:.2f}. У нас нет оснований отвергнуть нулевую гипотезу.'.format(alpha))\n",
    "\n",
    "# Тест на равенство дисперсий\n",
    "# p-value = 0.340\n",
    "# Дисперсии одинаковы, в stats.ttest_ind нужно использовать параметр equal_var=True.\n",
    "\n",
    "# Тест на равенство средних\n",
    "# p-value = 0.260\n",
    "# p-значение больше, чем заданный уровень значимости 0.05. У нас нет оснований отвергнуть нулевую гипотезу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                        ОДНОФАКТОРНЫЙ ДИСПЕРСИОННЫЙ АНАЛИЗ (ANOVA) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# задаём уровень значимости\n",
    "alpha = 0.05\n",
    "\n",
    "# загружаем данные\n",
    "group_zaryad = [31, 38, 30, 46, 40, 36, 38, 44, 43, 39, 36, 41, 37, 35, 38, 35, 38, 38, 42, 34]\n",
    "group_planeta = [36, 45, 41, 41, 35, 32, 34, 42, 48, 43, 41, 39, 35, 34, 52, 42, 44, 43, 35, 43]\n",
    "group_energiya = [35, 37, 39, 49, 45, 26, 46, 32, 49, 41, 48, 41, 47, 37, 45, 41, 43, 38, 40, 43]\n",
    "\n",
    "# проводим тест Левена на равенство дисперсий\n",
    "print('Тест на равенство дисперсий')\n",
    "result = stats.levene(group_zaryad, group_planeta, group_energiya)\n",
    "p = result[1]\n",
    "print('p-value = {:.3f}'.format(p))\n",
    "\n",
    "# интерпретируем результат\n",
    "if p <= alpha:\n",
    "    print('Дисперсии не одинаковы, нужно использовать непараметрический тест')\n",
    "else:\n",
    "    print('Дисперсии одинаковы, мы можем использовать тест ANOVA')\n",
    "\n",
    "# проводим тест на сравнение средних в группах\n",
    "print('\\nТест на равенство средних')\n",
    "_, p = stats.f_oneway(group_zaryad, group_planeta, group_energiya)\n",
    "\n",
    "print('p-value = {:.3f}'.format(p))\n",
    "\n",
    "# интерпретируем результат\n",
    "if p <= alpha:\n",
    "    print('p-значение меньше, чем заданный уровень значимости {:.2f}. Отвергаем нулевую гипотезу.'.format(alpha))\n",
    "else:\n",
    "    print('p-значение больше, чем заданный уровень значимости {:.2f}. У нас нет оснований отвергнуть нулевую гипотезу.'.format(alpha))\n",
    "\n",
    "# Тест на равенство дисперсий\n",
    "# p-value = 0.303\n",
    "# Дисперсии одинаковы, мы можем использовать тест ANOVA\n",
    "\n",
    "# Тест на равенство средних\n",
    "# p-value = 0.141\n",
    "# p-значение больше, чем заданный уровень значимости 0.05. У нас нет оснований отвергнуть нулевую гипотезу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                                          ПАРНЫЙ T-КРИТЕРИЙ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "# задаём уровень значимости\n",
    "alpha = 0.05 \n",
    "\n",
    "# загружаем данные\n",
    "data_zaryad = np.array([41, 34, 35, 47, 39, 42, 36, 43, 48, 38, 36, 47, 39, 32, 45, 40, 36, 39, 42, 46])\n",
    "data_planeta = np.array([45, 42, 40, 43, 44, 41, 43, 39, 45, 45, 40, 43, 41, 42, 41, 41, 43, 46, 45, 42])\n",
    "\n",
    "# проводим тест\n",
    "_, p = stats.ttest_rel(data_planeta, data_zaryad, alternative='greater')\n",
    "print('p-value = {:.3f}'.format(p))\n",
    "\n",
    "# интерпретируем результат\n",
    "if p <= alpha:\n",
    "    print('p-значение меньше, чем заданный уровень значимости {:.2f}. Отвергаем нулевую гипотезу.'.format(alpha))\n",
    "else:\n",
    "    print('p-значение больше, чем заданный уровень значимости {:.2f}. У нас нет оснований отвергнуть нулевую гипотезу.'.format(alpha))\n",
    "# p-value = 0.023\n",
    "# p-значение меньше, чем заданный уровень значимости 0.05. Отвергаем нулевую гипотезу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                            ОДНОФАКТОРНЫЙ ДИСПЕРСИОННЫЙ АНАЛИЗ (ANOVA) С ПОВТОРНЫМИ ИЗМЕРЕНИЯМИ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "\n",
    "# задаём уровень значимости\n",
    "alpha = 0.05 \n",
    "\n",
    "# создаём датасет\n",
    "data = pd.DataFrame({'group': np.repeat(['Заряд', 'Планета', 'Энергия'], 5),\n",
    "                          'object_id': np.tile([1, 2, 3, 4, 5], 3),                          \n",
    "                          'value': [36, 45, 41, 41, 35, 32, 34, 42, 48, 43, 41, 39, 35, 34, 52]})\n",
    "\n",
    "\n",
    "# проводим тест\n",
    "print(AnovaRM(data=data, depvar='value', subject='object_id', within=['group']).fit())\n",
    "\n",
    "#              Anova\n",
    "# ==================================\n",
    "#       F Value Num DF Den DF Pr > F\n",
    "# ----------------------------------\n",
    "# group  0.0100 2.0000 8.0000 0.9900\n",
    "# =================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                   ------------------------------------НЕПАРАМЕТРИЧЕСКИЕ ТЕСТЫ---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                              КРИТЕРИЙ ЗНАКОВ (ДЛЯ ОДНОЙ ГРУППЫ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.descriptivestats import sign_test\n",
    "\n",
    "# задаём уровень значимости\n",
    "alpha = 0.05 \n",
    "\n",
    "# загружаем данные\n",
    "data = [55, 53, 60, 49, 45, 57, 46, 53, 59, 53, 53, 55, 42, 41, 59, 43, 47, 60, 50, 57, 59, 56, 52, 48, 59, 53, 59, 50, 59, 59]\n",
    "\n",
    "# проводим тест\n",
    "_, p = sign_test(data, 60)\n",
    "\n",
    "print('p-value = {:.3f}'.format(p))\n",
    "\n",
    "# интерпретируем результат\n",
    "if p <= alpha:\n",
    "    print('p-значение меньше, чем заданный уровень значимости {:.2f}. Отвергаем нулевую гипотезу.'.format(alpha))\n",
    "else:\n",
    "    print('p-значение больше, чем заданный уровень значимости {:.2f}. У нас нет оснований отвергнуть нулевую гипотезу.'.format(alpha))\n",
    "\n",
    "# p-value = 0.000\n",
    "# p-значение меньше, чем заданный уровень значимости 0.05. Отвергаем нулевую гипотезу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                   U-КРИТЕРИЙ МАННА — УИТНИ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# задаём уровень значимости\n",
    "alpha = 0.05 \n",
    "\n",
    "# загружаем данные\n",
    "data_chat_bot = [55, 53, 60, 49, 45, 57, 46, 53, 59, 53, 53, 55, 42, 41, 59, 43, 47, 60, 50, 57, 59, 56, 52, 48, 59, 53, 59, 50, 59, 59]\n",
    "data_operator = [72, 80, 66, 72, 75, 71, 73, 71, 75, 68, 63, 68, 62, 65, 77, 66, 67, 62, 60, 74, 61, 67, 61, 63, 62, 79, 61, 63, 62, 63]\n",
    "\n",
    "# проводим тест\n",
    "_, p = stats.mannwhitneyu(data_chat_bot, data_operator)\n",
    "\n",
    "print('p-value = {:.3f}'.format(p))\n",
    "\n",
    "# интерпретируем результат\n",
    "if p <= alpha:\n",
    "    print('p-значение меньше, чем заданный уровень значимости {:.2f}. Отвергаем нулевую гипотезу.'.format(alpha))\n",
    "else:\n",
    "    print('p-значение больше, чем заданный уровень значимости {:.2f}. У нас нет оснований отвергнуть нулевую гипотезу.'.format(alpha))\n",
    "\n",
    "# p-value = 0.000\n",
    "# p-значение меньше, чем заданный уровень значимости 0.05. Отвергаем нулевую гипотезу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                     КРИТЕРИЙ УИЛКОКСОНА"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# задаём уровень значимости\n",
    "alpha = 0.05 \n",
    "\n",
    "# загружаем данные\n",
    "data_chat_bot = [71, 97, 71, 97, 83, 90, 83, 94, 88, 76, 79, 99, 82, 85, 93, 78, 76, 87, 73, 72, 89, 89, 71, 86, 78, 93, 86, 95, 83, 73]\n",
    "data_operator = [114, 112, 115, 124, 101, 108, 104, 109, 103, 115, 100, 129, 120, 129, 117, 125, 112, 105, 128, 107, 120, 108, 129, 100, 116, 105, 128, 128, 120, 106]\n",
    "\n",
    "# проводим тест\n",
    "_, p = stats.wilcoxon(data_chat_bot, data_operator, alternative = 'less')\n",
    "\n",
    "print('p-value = {:.3f}'.format(p))\n",
    "\n",
    "# интерпретируем результат\n",
    "if p <= alpha:\n",
    "    print('p-значение меньше, чем заданный уровень значимости {:.2f}. Отвергаем нулевую гипотезу.'.format(alpha))\n",
    "else:\n",
    "    print('p-значение больше, чем заданный уровень значимости {:.2f}. У нас нет оснований отвергнуть нулевую гипотезу.'.format(alpha))\n",
    "\n",
    "# p-value = 0.000\n",
    "# p-значение меньше, чем заданный уровень значимости 0.05. Отвергаем нулевую гипотезу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                  КРИТЕРИЙ КРАСКЕЛА — УОЛЛИСА"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# задаём уровень значимости\n",
    "alpha = 0.05 \n",
    "\n",
    "# загружаем данные\n",
    "data_basic = [106, 96, 105, 119, 91, 118, 108, 98, 103, 102, 98, 97, 104, 100, 94, 94, 98, 103, 95, 93, 118, 91, 96, 115, 119, 111, 102, 118, 91, 98 ]\n",
    "data_silver = [96, 95, 102, 103, 96, 120, 97, 112, 108, 90, 99, 93, 91, 91, 119, 95, 110, 108, 117, 99, 100, 99, 119, 98, 101, 95, 118, 110, 114, 116]\n",
    "data_gold = [99, 106, 92, 97, 98, 95, 119, 120, 116, 93, 102, 109, 98, 99, 100, 113, 91, 96, 119, 96, 95, 112, 111, 110, 102, 112, 105, 93, 111, 111]\n",
    "\n",
    "# проводим тест\n",
    "_, p = stats.kruskal(data_basic, data_silver, data_gold)\n",
    "\n",
    "print('p-value = {:.3f}'.format(p))\n",
    "\n",
    "# интерпретируем результат\n",
    "if p <= alpha:\n",
    "    print('p-значение меньше, чем заданный уровень значимости {:.2f}. Отвергаем нулевую гипотезу.'.format(alpha))\n",
    "else:\n",
    "    print('p-значение больше, чем заданный уровень значимости {:.2f}. У нас нет оснований отвергнуть нулевую гипотезу.'.format(alpha))\n",
    "\n",
    "# p-value = 0.837\n",
    "# p-значение больше, чем заданный уровень значимости 0.05. У нас нет оснований отвергнуть нулевую гипотезу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                      КРИТЕРИЙ ФРИДМАНА"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "friedmanchisquare() got an unexpected keyword argument 'alternative'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\datascience\\IDE\\Блок 3. Разведывательный анализ данных\\zametki.ipynb Ячейка 41\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/datascience/IDE/%D0%91%D0%BB%D0%BE%D0%BA%203.%20%D0%A0%D0%B0%D0%B7%D0%B2%D0%B5%D0%B4%D1%8B%D0%B2%D0%B0%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B9%20%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85/zametki.ipynb#X55sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m data_gold \u001b[39m=\u001b[39m [\u001b[39m62\u001b[39m, \u001b[39m84\u001b[39m, \u001b[39m67\u001b[39m, \u001b[39m71\u001b[39m, \u001b[39m64\u001b[39m, \u001b[39m89\u001b[39m, \u001b[39m65\u001b[39m, \u001b[39m70\u001b[39m, \u001b[39m86\u001b[39m, \u001b[39m77\u001b[39m, \u001b[39m84\u001b[39m, \u001b[39m81\u001b[39m, \u001b[39m89\u001b[39m, \u001b[39m68\u001b[39m, \u001b[39m87\u001b[39m, \u001b[39m70\u001b[39m, \u001b[39m70\u001b[39m, \u001b[39m61\u001b[39m, \u001b[39m82\u001b[39m, \u001b[39m79\u001b[39m, \u001b[39m60\u001b[39m, \u001b[39m62\u001b[39m, \u001b[39m88\u001b[39m, \u001b[39m61\u001b[39m, \u001b[39m76\u001b[39m, \u001b[39m87\u001b[39m, \u001b[39m79\u001b[39m, \u001b[39m90\u001b[39m, \u001b[39m77\u001b[39m, \u001b[39m65\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/datascience/IDE/%D0%91%D0%BB%D0%BE%D0%BA%203.%20%D0%A0%D0%B0%D0%B7%D0%B2%D0%B5%D0%B4%D1%8B%D0%B2%D0%B0%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B9%20%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85/zametki.ipynb#X55sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# проводим тест\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/datascience/IDE/%D0%91%D0%BB%D0%BE%D0%BA%203.%20%D0%A0%D0%B0%D0%B7%D0%B2%D0%B5%D0%B4%D1%8B%D0%B2%D0%B0%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B9%20%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85/zametki.ipynb#X55sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m _, p \u001b[39m=\u001b[39m stats\u001b[39m.\u001b[39;49mfriedmanchisquare(data_basic, data_silver, data_gold, alternative\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mgreater\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/datascience/IDE/%D0%91%D0%BB%D0%BE%D0%BA%203.%20%D0%A0%D0%B0%D0%B7%D0%B2%D0%B5%D0%B4%D1%8B%D0%B2%D0%B0%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B9%20%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85/zametki.ipynb#X55sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mp-value = \u001b[39m\u001b[39m{:.3f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(p))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/datascience/IDE/%D0%91%D0%BB%D0%BE%D0%BA%203.%20%D0%A0%D0%B0%D0%B7%D0%B2%D0%B5%D0%B4%D1%8B%D0%B2%D0%B0%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B9%20%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85/zametki.ipynb#X55sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# интерпретируем результат\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: friedmanchisquare() got an unexpected keyword argument 'alternative'"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# задаём уровень значимости\n",
    "alpha = 0.05 \n",
    "\n",
    "# загружаем данные\n",
    "data_basic = [113, 115, 108, 104, 107, 96, 114, 103, 103, 120, 92, 103, 120, 100, 110, 106, 112, 99, 118, 113, 102, 94, 92, 109, 91, 113, 95, 107, 110, 103]\n",
    "data_silver = [89, 80, 95, 77, 82, 98, 84, 83, 73, 93, 89, 78, 90, 73, 83, 73, 84, 90, 75, 75, 86, 88, 72, 72, 96, 75, 87, 99, 80, 82]\n",
    "data_gold = [62, 84, 67, 71, 64, 89, 65, 70, 86, 77, 84, 81, 89, 68, 87, 70, 70, 61, 82, 79, 60, 62, 88, 61, 76, 87, 79, 90, 77, 65]\n",
    "\n",
    "# проводим тест\n",
    "_, p = stats.friedmanchisquare(data_basic, data_silver, data_gold)\n",
    "\n",
    "print('p-value = {:.3f}'.format(p))\n",
    "\n",
    "# интерпретируем результат\n",
    "if p <= alpha:\n",
    "    print('p-значение меньше, чем заданный уровень значимости {:.2f}. Отвергаем нулевую гипотезу.'.format(alpha))\n",
    "else:\n",
    "    print('p-значение больше, чем заданный уровень значимости {:.2f}. У нас нет оснований отвергнуть нулевую гипотезу.'.format(alpha))\n",
    "\n",
    "# p-value = 0.000\n",
    "# p-значение меньше, чем заданный уровень значимости 0.05. Отвергаем нулевую гипотезу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                         ----------------       Статистические тесты для категориальных признаков---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                          КРИТЕРИЙ ХИ-КВАДРАТ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "\n",
    "# задаём уровень значимости\n",
    "alpha = 0.05 \n",
    "\n",
    "data = pd.read_csv('/data/cat_variables_tarif_children.csv')\n",
    "\n",
    "# вычисляем таблицу сопряжённости\n",
    "table = pd.crosstab(data['Тариф'], data['Наличие детей'])\n",
    "\n",
    "# проводим тест\n",
    "_, p, _, _ = stats.chi2_contingency(table)\n",
    "\n",
    "print('p-value = {:.3f}'.format(p))\n",
    "\n",
    "# интерпретируем результат\n",
    "if p <= alpha:\n",
    "    print('p-значение меньше, чем заданный уровень значимости {:.2f}. Отвергаем нулевую гипотезу.'.format(alpha))\n",
    "else:\n",
    "    print('p-значение больше, чем заданный уровень значимости {:.2f}. У нас нет оснований отвергнуть нулевую гипотезу.'.format(alpha))\n",
    "\n",
    "# p-value = 0.373\n",
    "# p-значение больше, чем заданный уровень значимости 0.05. У нас нет оснований отвергнуть нулевую гипотезу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                             КРИТЕРИЙ МАК-НЕМАРА"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "import pandas as pd\n",
    "\n",
    "# задаём уровень значимости\n",
    "alpha = 0.05 \n",
    "\n",
    "data = pd.read_csv('/data/cat_variables_usage.csv')\n",
    "\n",
    "# вычисляем таблицу сопряжённости\n",
    "table = pd.crosstab(data['До'], data['После'])\n",
    "\n",
    "# проводим тест\n",
    "res = mcnemar(table)\n",
    "\n",
    "# извлекаем значение p-value из результатов теста\n",
    "p = res.pvalue\n",
    "\n",
    "print('p-value = {:.3f}'.format(p))\n",
    "\n",
    "# интерпретируем результат\n",
    "if p <= alpha:\n",
    "    print('p-значение меньше, чем заданный уровень значимости {:.2f}. Отвергаем нулевую гипотезу.'.format(alpha))\n",
    "else:\n",
    "    print('p-значение больше, чем заданный уровень значимости {:.2f}. У нас нет оснований отвергнуть нулевую гипотезу.'.format(alpha))\n",
    "\n",
    "# p-value = 0.013\n",
    "# p-значение меньше, чем заданный уровень значимости 0.05. Отвергаем нулевую гипотезу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                                 REPLACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание датасета\n",
    "data = pd.DataFrame([\"среднее профессиональное\", \"высшее образование\", \"основное общее\", \"среднее общее\", \"основное общее\", \"среднее профессиональное\"], columns=['Уровень образования']) \n",
    "display(data)\n",
    "\n",
    "# перевод категориального признака в количественный\n",
    "data['Уровень образования'] = data['Уровень образования'].replace([\"основное общее\", \"среднее общее\", \"среднее профессиональное\", \"высшее образование\"], [1, 2, 3, 4])\n",
    "display(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb4569285eef3a3450cb62085a5b1e0da4bce0af555edc33dcf29baf3acc1368"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
